%% ====================================================================
\section{Method}
\label{section:method}
%% ====================================================================

The Mosler secure computing environment~\cite{mosler} enables
scientists to carry out research on \emph{sensitive data}, \eg data
related to personal health.
%
For each project in Mosler, a set of virtual machines (VMs) is
created, which the users access via a secured encrypted connection.
% All communication is encrypted.

When a VM is started, it ``books'' predefined resources, such as CPU
cores and disk space, and when all the hardware cores are booked, we
say that the cloud cluster is full. In such a case, we are interested
in extending the set of VMs with external ones running in another
cluster, and in our case, the extra cluster is located in another
country.

\begin{figure}[b]
  \centering
  \input{img/overview}
  \caption{Overview of the project resources}
  \label{figure:overview}
\end{figure}

We build a temporary cluster in Sweden, which we refer to as Knox, and
use the ePouta cluster~\cite{epouta} in Finland to extend a project
running on Knox. As a first step, we isolate the project from any
other project, but do not encrypt the communications, \ie the
environment manipulates non-sensitive data.
%
The VMs infrastructure is shaped as in
Figure~\ref{figure:overview}. We boot on Knox:
\begin{itemize}
\item a Virtual Router,
\item a DHCP server, providing network settings to the Knox VMs,
\item 3 VMs for computations
\item a storage node
\item a \emph{supernode} where we connect and run the tests
\end{itemize}
On ePouta, we boot:
\begin{itemize}
\item a DHCP server, providing network settings to the ePouta VMs,
\item 3 VMs for computations
\end{itemize}

We connect the two clusters with a 1Gb/s fiber-link and provide a
local network between the VMs, which can communicate across the
Swedish--Finnish border transparently.
%
Note that the link might be shared by other projects, but VMs from
other projects cannot reach the above-mentioned VMs.
%
This isolation is provided by VLAN encapsulation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We aim at running realistic workflows on the extended cluster, and see
whether we can notice a significant slowdown when computations are
scheduled on VMs across borders.
%
We choose to run the \href{https://github.com/SciLifeLab/CAW}{Cancer
  Analysis Workflow}~\cite{caw} from SciLifeLab and the
\href{https://github.com/NBISweden/wgs-structvar}{Whole Genome
  Sequencing Structural Variation Pipeline}~\cite{caw} from
\href{http://www.nbis.se}{NBIS}.
%
We denote them here CAW and WGS, respectively.
%
CAW is a pipeline for variant calling of tumor data and WGS is a
pipeline for predicting and annotating structural variations in the
human genome.
%
Yet, we only use non-sensitive data, here in the first step.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Moreover, with this approach, where the computations might be
scheduled in Finland, while the data have to reside in Sweden, we
suspect that disk access and even the network itself would be a
bottleneck. So, we run some further tests to stress both aspects.
%
We use the program SOB~\cite{sob} to stress the filesystem, by reading
and writing an arbitrary number of files in different chunk sizes.
%
SOB also outputs useful performance numbers.
%
In order to test the network, we use iPerf3~\cite{iperf}, a tool for
active measurements of the maximum achievable bandwidth on IP
networks.
%
For each run, the tool reports the bandwidth, loss, and several other
parameters related to how well the link was used.
%
We instantiate a data communication between two VMs, one on Knox and
one on ePouta and test the connection.
%
We then repeat the same test with three connections in parallel over
pairwise-connected VMs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
After running the tests, described in
Section~\ref{section:experiments}, we notice no significant slowdown
on the computations for the pipelines, and the stress-tests reveal
that (i)~disk~access is not slower and (ii)~the~link is almost fully
used.
%
Computations and tests do not notice whether they are performed in
Finland or in Sweden.
%
In other words, this is a very positive outcome where data traffic and
computations are carried out as if the extended VMs were all located
in the same country.
%
Computations are actually running slightly faster in Finland, since
the hardware in ePouta is better than the one in Knox.
%
It is probably possible to fine-tune kernel settings
to get even further performance and a seamless connection.
%
The remaining step dealing with sensitive data can thus be ignored.
%
It is worth noting that the link capacity must be adjusted in case the
number of VMs communicating through the link increases.
