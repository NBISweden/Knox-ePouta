%% ====================================================================
\section{Method}
\label{section:method}
%% ====================================================================

The Mosler secure computing environment~\cite{mosler} enables
scientists to carry out research on \emph{sensitive data}, \eg
personal data related to health.
%
For each project on the system, a set of virtual machines (VMs) is
booted, which the users access via a secured connection. All
communication is encrypted.

When a VM is started, it ``books'' predefined CPU resources and disk
space and when all the hardware cores are booked, we say that the
cloud cluster is full. In such a case, we are interested in extending
the set of VMs with external ones running in another cluster, and in
our case, the extra cluster is located in another country.

\begin{figure}[b]
  \centering
  \tikz\draw circle(2cm) node{wow...impressive!};
  %\input{img/overview}
  \caption{Overview of the project resources}
  \label{figure:overview}
\end{figure}

We build a temporary cluster in Sweden, which we refer to as Knox, and
use the ePouta cluster~\cite{epouta} in Finland to extend a project
running on Knox. As a first step, we isolate the project from any
other project, but do not encrypt the communications, \ie the
environment manipulates non-sensitive data.
%
The VMs infrastructure is shaped as in
Figure~\ref{figure:overview}. We boot on Knox:
\begin{itemize}
\item a Virtual Router,
\item a DHCP server, providing network settings to the Knox VMs,
\item 3 VMs for computations
\item a storage node
\item a \emph{supernode} where we connect and run the tests
\end{itemize}
On ePouta, we boot:
\begin{itemize}
\item a DHCP server, providing network settings to the ePouta VMs,
\item 3 VMs for computations
\end{itemize}

We connect the two clusters with a 1GB/s fiber-link. We provide a
local network between the VMs, which can communicate across borders
transparently.
%
Note that the link might be shared by other projects, but VMs from
other projects cannot reach the above-mentioned VMs.
%
This isolation is provided by VLAN encapsulation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We aim at running realistic workflows on the extended cluster, and see
whether we can notice a significant slowdown when computations are
scheduled on VMs across borders.
%
We choose to run the \href{https://github.com/SciLifeLab/CAW}{Cancer
  Analysis Workflow}~\cite{caw} from SciLifeLab and the
\href{https://github.com/NBISweden/wgs-structvar}{Whole Genome
  Sequencing Structural Variation Pipeline}~\cite{caw} from
\href{http://www.nbis.se}{NBIS}.
%
We denote them here CAW and WGS, respectively.
%
CAW is a pipeline for variant calling of tumor data and WGS is a
pipeline for predicting and annotating structural variations in the
human genome.
%
Yet, we only use non-sensitive data, here in the first step.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Moreover, in this approach, where the computations might be scheduled
in Finland, while the data have to reside in Sweden, we suspect that
disk access and even the network itself would be a bottleneck. So, we
run some further tests to stress both aspects.
%
We use the program SOB~\cite{sob} to stress the filesystem, by reading
and writing an arbitrary number of files in different chunk sizes.
%
SOB also outputs useful performance numbers.
%
In order to test the network, we use iPerf3~\cite{iperf}, a tool for
active measurements of the maximum achievable bandwidth on IP
networks.
%
For each run, the tool reports the bandwidth, loss, and several other
parameters related to how well the link was used.
%
We instantiate a data communication between two VMs, one on Knox and
one on ePouta and test the connection.
%
We then repeat the same test with three connections in parallel over
pairwise-connected VMs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
After running the tests, described in
Section~\ref{section:experiments}, we notice no significant slowdown
on the computations for the pipelines, and the stress-tests reveal
that (i)~disk~access is not slower and (ii)~the~link is almost fully
used.
%
Computations and tests do not notice whether they are performed in
Finland or in Sweden.
%
In other words, this is a very positive outcome where data traffic and
computations are carried out as if the extended VMs were all located
in the same country.
%
Computations are actually running slightly faster in Finland, since
the hardware in ePouta is better than the one in Knox.
%
It is probably possible to fine-tune kernel settings
to get even further performance and a seamless connection.
%
The remaining step dealing with sensitive data can thus be ignored.
%
You can refer to the
\href{https://github.com/NBISweden/Knox-ePouta}{NBIS GitHub
  repository}~\cite{nbis-knox-epouta} for the source code, in order to
reproduce the setup and re-run the tests.
%
It is worth noting that the link capacity must be adjusted in case the
number of VMs communicating through the link increases.
