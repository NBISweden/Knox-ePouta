\section{Appendices}
%
\subsection{Complete SOB results}
\label{appendix:SOB}

We report, in the tables below, the writing times for each test from
Section~\ref{experiments:NFS}, on each VM of the chosen set.
%
The first row of each table specifies, in order, which nodes were used
in the tests.
%
For test~\ref{experiments:SOB:test:big} and
\ref{experiments:SOB:test:cache}, the second line represents the
reading time. In parenthesis, we indicate the bandwidth (rounded to
the closest first decimal).%

\noindent%
\resultpartition%
{{knox1}{knox2}{knox3}}%
{{ 212 }{ 48.4   }{ 487 }{ 21.0   }{ 492 }{ 20.8   }}%
{{ 166 }{ 61.8   }{ 219 }{ 46.7   }{ 208 }{ 49.3   }}%
{{  55 }{ 9.0    }{  60 }{ 8.4    }{  60 }{ 8.3    }}%
{{ 204 }{ 31.3   }{ 237 }{ 27.0   }{ 243 }{ 26.4   }}%
{{  26 }{ 33.7   }{  39 }{ 26.3   }{  37 }{ 27.8   }}%
{{ 0.3 }{ 3330.5 }{ 0.3 }{ 3379.5 }{ 0.3 }{ 3703.7 }}

\noindent%
\resultpartition%
{{ePouta3}{ePouta2}{epouta1}}%
{{ 527 }{ 19.4   }{ 399 }{ 25.7   }{ 363 }{ 28.2   }}%
{{ 217 }{ 47.1   }{ 300 }{ 34.1   }{ 287 }{ 35.7   }}%
{{  79 }{ 6.3    }{  72 }{ 7.0    }{  75 }{ 6.7    }}%
{{ 267 }{ 24.0   }{ 259 }{ 24.8   }{ 267 }{ 24.0   }}%
{{  31 }{ 33.4   }{  38 }{ 26.9   }{  34 }{ 29.8   }}%
{{ 0.4 }{ 2583.8 }{ 0.3 }{ 3702.7 }{ 0.3 }{ 4053.6 }}

\noindent%
\resultpartition%
{{knox1}{ePouta1}{epouta2}}%
{{ 315 }{ 32.5   }{ 529 }{ 19.3   }{ 449 }{ 22.8   }}%
{{ 268 }{ 38.2   }{ 226 }{ 45.4   }{ 271 }{ 37.8   }}%
{{  50 }{ 9.9    }{  77 }{ 6.5    }{  75 }{ 6.7    }}%
{{ 193 }{ 33.2   }{ 250 }{ 25.6   }{ 247 }{ 25.9   }}%
{{  18 }{ 57.4   }{  37 }{ 27.6   }{  35 }{ 28.9   }}%
{{ 0.3 }{ 3357.8 }{ 0.3 }{ 3758.1 }{ 0.2 }{ 4132.1 }}

\noindent%
\resultpartition%
{{knox3}{knox2}{epouta1}}%
{{ 317 }{ 32.3   }{ 301 }{ 34.1   }{ 695 }{ 14.7   }}%
{{ 227 }{ 45.1   }{ 236 }{ 43.4   }{ 104 }{ 98.0   }}%
{{  62 }{  8.1   }{  62 }{  8.1   }{  81 }{  6.2   }}%
{{ 241 }{ 26.5   }{ 244 }{ 26.2   }{ 317 }{ 20.2   }}%
{{  29 }{ 35.5   }{  30 }{ 33.9   }{  42 }{ 24.4   }}%
{{ 0.3 }{ 3752.7 }{ 0.3 }{ 3347.1 }{ 0.3 }{ 3372.9 }}

\noindent%
\resultpartition%
{{epouta3}{epouta1}{knox2}}%
{{ 529 }{ 19.3   }{ 520 }{ 19.7   }{ 190 }{ 53.9   }}%
{{ 211 }{ 48.5   }{ 220 }{ 46.5   }{ 169 }{ 60.7   }}%
{{  75 }{  6.6   }{  75 }{  6.7   }{  56 }{  9.0   }}%
{{ 296 }{ 21.6   }{ 303 }{ 21.1   }{ 202 }{ 31.7   }}%
{{  39 }{ 26.1   }{  39 }{ 26.0   }{  24 }{ 43.2   }}%
{{ 0.3 }{ 2936.8 }{ 0.2 }{ 4486.9 }{ 0.3 }{ 3419.9 }}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pitfalls and Caveats\\with Neutron Linux Bridges}
\label{appendix:secgroups}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\endinput %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section, we describe how the security rules are
implemented. This involves low-level details that are relevant to
understand pitfalls in connecting the VMs from different clouds
together.

When we display the \kw{FORWARD} chain, we see that OpenStack adds a
``relay'' chain, named \kw{neutron-linuxbri-FORWARD}.

\codeblock{iptables-forward.sh}

All rules are in fact in that relay chain. If the traffic, whether
inwards or outwards, goes through the VM interface, via the tap
interfaces (\ie the interfaces in the root namespace connected to the
bridges), it is redirected to the security group chain.

\codeblock{iptables-forward-neutron.sh}

The security group chain gathers rules about incoming and outgoing
traffic from the VMs. Surprisingly, that chain forks and redirects the
traffic to an \emph{incoming} or another \emph{outgoing} chain. If
those latter chains do not filter the traffic, the packets are then
accepted.

\codeblock{iptables-sg-chain.sh}

Let us now inspect the outgoing chain onto a particular VM. The name
of such a chain starts with \emph{neutron-linuxbri-\textbf{o}}). The
chain begins by allowing traffic from the DHCP client (by returning to
the previous chain, which accepts the traffic).

\codeblock{iptables-neutron-sg-input.sh}

Otherwise, it jumps to a \emph{source chain} (which name starts with
\emph{neutron-linuxbri-\textbf{s}}).

\codeblock{iptables-neutron-sg-source.sh}

The source chain filters out traffic that is not the proper pair of IP
and MAC address related to that VM. This is important since a VM
cannot then simply add a network or an interface and connect through
it. In the hypothetical scenario where that VM creates a bridge, the
MAC address of the bridge might flicker between the ones from the
added interfaces. Moreover, in another scenario where the VM network
is augmented with another local network, say \ip{192.168.0.0/24}, the
traffic would be filtered by the source chain. This is relevant in
case we want to implement on OpenStack installation inside VMs (such
as Mosler, or the so-called \emph{Triple-O}: OpenStack on OpenStack).

Back to the outgoing chain, after checking the allowed IP/MAC pair
(which can be updated through some Neutron commands), it checks for
established connections, or drops them if they are invalid. In other
cases, the filtering continues onto a \emph{fallback chain} which
simply drops that traffic.

\codeblock{iptables-neutron-sg-output.sh}

Finally, we observe that the OpenStack security rules, which we added
in Neutron, end up in the \emph{incoming chain} (which name starts
with \emph{neutron-linuxbri-\textbf{i}}). The DHCP traffic is allowed,
along with \kw{ping} and \kw{tcp} traffic (on all ports), from the IP
range \ip{10.101.0.0/16}. Some specific Neutron commands can allow
other network ranges, and this is where the rules would appear.

\codeblock{iptables-neutron-sg-input-2.sh}

In case the above \kw{ping} and \kw{tcp} rules were absent, the
traffic is then accepted if it comes from another VM on the
network. This is implemented with \emph{IPset}.

\codeblock{iptables-neutron-ipset.sh}

Notice here that the set contains the IP of the machines that were
booted on Knox, and not ePouta. We would have to update the IPset, or
update the plugin itself to automatically include the other VMs across
borders. It was not necessary since we had the ``All \kw{tcp} ports''
rule already in place.
